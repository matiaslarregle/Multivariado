{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oflM2UeU7AOO",
        "outputId": "35944de9-d7ec-4a77-a03f-9c4dde2da4e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  #para interactuar con Google Drive desde un entorno Colab.\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy scipy scikit-learn -y  #reinstalación controlada de paquetes fundamentales para ciencia de datos\n",
        "!pip install numpy==1.23.5 scipy==1.9.3 scikit-learn==1.2.2  #reinstalación controlada de paquetes fundamentales para ciencia de datos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iw695hN57nPL",
        "outputId": "b4af17cb-f454-4798-9af2-51e7e52efd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Found existing installation: scipy 1.15.3\n",
            "Uninstalling scipy-1.15.3:\n",
            "  Successfully uninstalled scipy-1.15.3\n",
            "Found existing installation: scikit-learn 1.6.1\n",
            "Uninstalling scikit-learn-1.6.1:\n",
            "  Successfully uninstalled scikit-learn-1.6.1\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting scipy==1.9.3\n",
            "  Downloading scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m137.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.4/33.4 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, scikit-learn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cvxpy 1.6.5 requires scipy>=1.11.0, but you have scipy 1.9.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.9.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.9.3 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.4.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "stumpy 1.13.0 requires scipy>=1.10, but you have scipy 1.9.3 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.9.3 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, but you have scipy 1.9.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.6 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.9.3 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 scikit-learn-1.2.2 scipy-1.9.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "11e6f13b49944bb6a599e95b4f903d40"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd    # Para manipulación de datos estructurados (DataFrames)\n",
        "import numpy as np      #Para operaciones numéricas eficientes\n",
        "from sklearn.model_selection import train_test_split   #Divide los datos en conjuntos de entrenamiento y prueba\n",
        "from sklearn.preprocessing import LabelEncoder         # Para codificar variables categóricas en numéricas\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix   #Calcula la precisión de las predicciones, Genera una matriz de confusión para evaluar el rendimiento\n",
        "import matplotlib.pyplot as plt    # para Visualización de Datos\n",
        "from scipy.stats import multivariate_normal  #Para trabajar con distribuciones normales multivariadas\n",
        "from sklearn.datasets import make_classification  # Para crear datasets de clasificación sintéticos\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report   #Calcula la precisión de las predicciones, Genera una matriz de confusión para evaluar el rendimiento\n",
        "\n",
        "# Cargar el dataset desde el archivo subido\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/dataset.csv\")\n",
        "\n",
        "# Mostrar columnas y detectar NaNs o infs\n",
        "print(\"Columnas del dataset:\", df.columns)\n",
        "print(\"Cantidad de NaNs por columna:\\n\", df.isna().sum())\n",
        "\n",
        "# Eliminar filas con NaNs o infinitos\n",
        "df = df.replace([np.inf, -np.inf], np.nan)  # Reemplaza infinitos por NaN\n",
        "df = df.dropna()  # Elimina cualquier fila con NaNs\n",
        "\n",
        "# Separar variables independientes y la etiqueta\n",
        "y = df['label']  # Cambiá 'label' si tu columna se llama diferente\n",
        "X = df.drop(columns=['label'])\n",
        "\n",
        "# Verificamos que no queden valores inválidos\n",
        "assert not np.isnan(X.values).any(), \"Todavía hay NaNs en X\"\n",
        "assert not np.isinf(X.values).any(), \"Todavía hay infinitos en X\"\n",
        "\n",
        "# Verificamos las columnas\n",
        "print(\"Columnas:\", df.columns)\n",
        "\n",
        "# Asegurarnos de que la columna objetivo se llama correctamente\n",
        "# Por ejemplo, puede llamarse 'genero', 'Label', 'género', etc.\n",
        "# Supongamos que es 'label', si no lo es cambiá esta línea:\n",
        "y = df['label']  # CAMBIAR si es otra columna, por ej: df['genero']\n",
        "X = df.drop(columns=['label'])\n",
        "\n",
        "# Codificar las etiquetas (si son strings como 'hombre', 'mujer')\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# División train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "class GDA:\n",
        "    def __init__(self):\n",
        "        # Parámetros iniciales\n",
        "        self.clases = None\n",
        "        self.mu = {}\n",
        "        self.sigma = {}\n",
        "        self.priors = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Obtengo las clases únicas\n",
        "        self.clases = np.unique(y)\n",
        "\n",
        "        for k in self.clases:\n",
        "            X_k = X[y == k]\n",
        "            # Media por clase\n",
        "            self.mu[k] = np.mean(X_k, axis=0)\n",
        "            # Matriz de covarianza\n",
        "            self.sigma[k] = np.cov(X_k, rowvar=False)\n",
        "            self.sigma[k] += np.eye(self.sigma[k].shape[0]) * 1e-6\n",
        "            # Probabilidad a priori\n",
        "            self.priors[k] = len(X_k) / len(X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Hago las predicciones\n",
        "        res = []\n",
        "\n",
        "        for x in X:\n",
        "            probs = {}\n",
        "            for k in self.clases:\n",
        "                prob_conjunta = (1/np.sqrt(np.linalg.det(self.sigma[k]))) * np.exp(-0.5* np.dot(np.dot((x-self.mu[k]),np.linalg.inv(self.sigma[k])),(x-self.mu[k]).T))\n",
        "\n",
        "                probs[k] = self.priors[k] * prob_conjunta\n",
        "\n",
        "            res.append(max(probs, key=probs.get))\n",
        "\n",
        "        return np.array(res)\n",
        "\n",
        "\n",
        "# Entrenar y evaluar\n",
        "gda = GDA()\n",
        "gda.fit(X_train, y_train)\n",
        "y_pred = gda.predict(X_test)\n",
        "\n",
        "# Resultados\n",
        "print(\"Exactitud en test:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Matriz de confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "# Exactitud (accuracy)\n",
        "print(\"Exactitud (accuracy):\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Matriz de confusión\n",
        "print(\"\\nMatriz de confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Reporte de clasificación (precision, recall, f1-score)\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npdss9h87nR2",
        "outputId": "40c92651-5d4e-4214-b533-d44e12400825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas del dataset: Index(['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n",
            "       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n",
            "       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx', 'mean_f0',\n",
            "       'min_f0', 'max_f0', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5',\n",
            "       'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12',\n",
            "       'mfcc_13', 'label'],\n",
            "      dtype='object')\n",
            "Cantidad de NaNs por columna:\n",
            " meanfreq    0\n",
            "sd          0\n",
            "median      0\n",
            "Q25         0\n",
            "Q75         0\n",
            "IQR         0\n",
            "skew        0\n",
            "kurt        0\n",
            "sp.ent      0\n",
            "sfm         0\n",
            "mode        0\n",
            "centroid    0\n",
            "meanfun     0\n",
            "minfun      0\n",
            "maxfun      0\n",
            "meandom     0\n",
            "mindom      0\n",
            "maxdom      0\n",
            "dfrange     0\n",
            "modindx     0\n",
            "mean_f0     2\n",
            "min_f0      2\n",
            "max_f0      2\n",
            "mfcc_1      0\n",
            "mfcc_2      0\n",
            "mfcc_3      0\n",
            "mfcc_4      0\n",
            "mfcc_5      0\n",
            "mfcc_6      0\n",
            "mfcc_7      0\n",
            "mfcc_8      0\n",
            "mfcc_9      0\n",
            "mfcc_10     0\n",
            "mfcc_11     0\n",
            "mfcc_12     0\n",
            "mfcc_13     0\n",
            "label       0\n",
            "dtype: int64\n",
            "Columnas: Index(['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n",
            "       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n",
            "       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx', 'mean_f0',\n",
            "       'min_f0', 'max_f0', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5',\n",
            "       'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12',\n",
            "       'mfcc_13', 'label'],\n",
            "      dtype='object')\n",
            "Exactitud en test: 0.5970149253731343\n",
            "Matriz de confusión:\n",
            "[[32  7]\n",
            " [47 48]]\n",
            "Exactitud (accuracy): 0.5970149253731343\n",
            "\n",
            "Matriz de confusión:\n",
            "[[32  7]\n",
            " [47 48]]\n",
            "\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    'Female'       0.41      0.82      0.54        39\n",
            "      'Male'       0.87      0.51      0.64        95\n",
            "\n",
            "    accuracy                           0.60       134\n",
            "   macro avg       0.64      0.66      0.59       134\n",
            "weighted avg       0.74      0.60      0.61       134\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar medias (mu) por clase\n",
        "print(\"Media (mu) por clase:\")\n",
        "for k in gda.mu:\n",
        "    print(f\"Clase {k} ({le.inverse_transform([k])[0]}):\")\n",
        "    print(gda.mu[k])\n",
        "    print()\n",
        "\n",
        "# Mostrar matrices de covarianza (sigma) por clase\n",
        "print(\"Matriz de covarianza (sigma) por clase:\")\n",
        "for k in gda.sigma:\n",
        "    print(f\"Clase {k} ({le.inverse_transform([k])[0]}):\")\n",
        "    print(gda.sigma[k])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9FI0hAs7nUH",
        "outputId": "8abb22f4-85cc-4674-c697-00ec03698d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media (mu) por clase:\n",
            "Clase 0 ('Female'):\n",
            "[ 3.73651970e+03  4.33628190e-02 -3.66135226e-03 -1.70659655e-02\n",
            "  7.11560431e-03  2.41815698e-02  6.22655074e-01  8.66210823e+00\n",
            "  4.47349872e+03  1.20837176e-02  0.00000000e+00  3.73651970e+03\n",
            "  3.27373515e-02  2.55827686e-03  1.25326572e-01  8.07915596e+03\n",
            "  1.82562023e+03  1.47240782e+04  1.28984580e+04  4.92700054e-01\n",
            "  1.51231654e+02  7.29639034e+01  3.47030634e+02 -3.82485979e+02\n",
            "  1.13592083e+02  8.68207337e+00  2.86823905e+01  8.79296792e+00\n",
            "  1.24616455e+01 -1.17190902e+01  1.24772706e+01 -2.36626997e+00\n",
            "  2.24904238e+00 -4.69968855e+00  4.12503263e+00 -1.92955482e+00]\n",
            "\n",
            "Clase 1 ('Male'):\n",
            "[ 3.82273410e+03  5.51984958e-02 -3.63604857e-03 -1.98935801e-02\n",
            "  9.55109549e-03  2.94446756e-02  6.14420313e-01  9.13818497e+00\n",
            "  4.56237458e+03  1.42301809e-02  0.00000000e+00  3.82273410e+03\n",
            "  4.12131579e-02  2.51914684e-03  1.52704277e-01  8.17378764e+03\n",
            "  1.44749768e+03  1.51911041e+04  1.37436064e+04  5.60372249e-01\n",
            "  3.66340805e+02  2.36470308e+02  6.12499903e+02 -3.68004413e+02\n",
            "  1.16095394e+02  1.92443562e+01  3.29808521e+01  1.08603918e+01\n",
            "  1.82047421e+01 -8.46125158e+00  1.32812356e+01  5.40367444e-01\n",
            "  5.66184636e+00 -7.46612109e+00  6.04043378e+00 -8.33947186e-01]\n",
            "\n",
            "Matriz de covarianza (sigma) por clase:\n",
            "Clase 0 ('Female'):\n",
            "[[ 2.18742085e+06 -6.64594783e+00 -5.62206256e-01 ... -8.27120337e+03\n",
            "   9.15228690e+03  4.65471163e+02]\n",
            " [-6.64594783e+00  6.20771182e-04 -8.81952230e-06 ...  2.78420413e-02\n",
            "  -4.57550742e-02 -1.94436802e-02]\n",
            " [-5.62206256e-01 -8.81952230e-06  2.73821942e-06 ...  1.10127999e-03\n",
            "  -2.86062382e-03  9.46750708e-04]\n",
            " ...\n",
            " [-8.27120337e+03  2.78420413e-02  1.10127999e-03 ...  7.54631500e+01\n",
            "  -3.82258099e+01 -1.36316570e+01]\n",
            " [ 9.15228690e+03 -4.57550742e-02 -2.86062382e-03 ... -3.82258099e+01\n",
            "   7.40304473e+01 -1.08359229e+01]\n",
            " [ 4.65471163e+02 -1.94436802e-02  9.46750708e-04 ... -1.36316570e+01\n",
            "  -1.08359229e+01  4.00243962e+01]]\n",
            "\n",
            "Clase 1 ('Male'):\n",
            "[[ 2.10206002e+06 -2.18700976e+01 -4.53880479e-01 ... -6.69106267e+03\n",
            "   7.55414154e+03  9.13955138e+02]\n",
            " [-2.18700976e+01  1.75241071e-03 -6.11280659e-06 ...  6.46719356e-02\n",
            "  -9.84588306e-02 -1.41177207e-02]\n",
            " [-4.53880479e-01 -6.11280659e-06  3.12153291e-06 ...  1.46041782e-03\n",
            "  -2.76581148e-03 -1.76623068e-04]\n",
            " ...\n",
            " [-6.69106267e+03  6.46719356e-02  1.46041782e-03 ...  5.56492189e+01\n",
            "  -2.54918677e+01 -9.51167280e+00]\n",
            " [ 7.55414154e+03 -9.84588306e-02 -2.76581148e-03 ... -2.54918677e+01\n",
            "   6.11087854e+01 -1.27126336e+01]\n",
            " [ 9.13955138e+02 -1.41177207e-02 -1.76623068e-04 ... -9.51167280e+00\n",
            "  -1.27126336e+01  4.12685476e+01]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion:\n",
        "\n",
        "El modelo LDA superó al QDA en accuracy (0.649 vs 0.597), demostrando mejor rendimiento. Al analizar las matrices de covarianza, se observa que el LDA presenta mayor estabilidad numérica, ya que promedia las matrices de ambas clases (principio de homocedasticidad), evitando el sobreajuste del QDA. Las matrices individuales del QDA (Female/Male) muestran diferencias menores al 10% en sus componentes principales (ej: [0,0] = 2.19e6 vs 2.10e6), lo que confirma que la covarianza compartida del LDA es válida. Esto, sumado a la simplicidad del modelo, hace que el QDA —más complejo y con peor generalización— no sea justificable en este caso. Por lo tanto, cuando las clases comparten estructura de covarianza, LDA es preferible por eficiencia y robustez."
      ],
      "metadata": {
        "id": "Rj3KJOLU77j-"
      }
    }
  ]
}