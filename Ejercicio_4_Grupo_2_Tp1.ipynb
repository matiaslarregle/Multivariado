{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqP9jVh-SYqv",
        "outputId": "a09b3049-36bb-4895-de9b-a10ebae82ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Conexión con Google Drive (específico para Google Colab)\n",
        "from google.colab import drive  # Permite montar Google Drive en el entorno Colab\n",
        "drive.mount('/content/drive')  # Monta la carpeta de Google Drive en la ruta /content/drive\n",
        "\n",
        "# Descarga del modelo de idioma español para spaCy (ejecuta solo una vez)\n",
        "!python -m spacy download es_core_news_sm\n",
        "\n",
        "# Importaciones de NLTK\n",
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer  # Tokenizador avanzado para palabras\n",
        "from nltk.tokenize import sent_tokenize  # Tokenizador de oraciones\n",
        "from nltk.corpus import stopwords  # Lista de palabras vacías (stopwords)\n",
        "from nltk.stem import WordNetLemmatizer  # Lematizador (reducción a forma canónica)\n",
        "from nltk.stem import SnowballStemmer  # Stemmer para español (reducción a raíz)\n",
        "from sklearn.utils import resample # permite realizar remuestreo (bootstrap) de conjuntos de datos\n",
        "import math                        # importa el módulo math de Python, que proporciona funciones matemáticas básicas.\n",
        "from collections import defaultdict # subclase del diccionario estándar de Python que proporciona un valor predeterminado para las claves que no existen, evitando así errores KeyError.\n",
        "from sklearn.metrics import classification_report  #Calcula la precisión de las predicciones,f1-score, recall y support.\n",
        "import pandas as pd  # Biblioteca para el análisis y manipulación de datos tabulares\n",
        "from sklearn.metrics import accuracy_score  #Calcula la precisión de las predicciones\n",
        "\n",
        "# Importación de spaCy\n",
        "import spacy  # Biblioteca avanzada de NLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar 'punkt' para tokenización de oraciones\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download([\n",
        "    'punkt',\n",
        "    'stopwords',\n",
        "    'wordnet',\n",
        "    'averaged_perceptron_tagger'\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13Ei4CVYTFPi",
        "outputId": "a951a9e9-ee1e-411b-879a-44c0f02470f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar CSV ignorando líneas corruptas\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/US-Economic-News.csv\", encoding='latin1')\n",
        "\n",
        "# Mostrar las primeras filas\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peURl2BVS-_6",
        "outputId": "ae0c0c3f-9488-4fb9-cac9-093946a993fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
            "0  842613455    False   finalized                   3     12/5/15 17:48   \n",
            "1  842613456    False   finalized                   3     12/5/15 16:54   \n",
            "2  842613457    False   finalized                   3      12/5/15 1:59   \n",
            "3  842613458    False   finalized                   3      12/5/15 2:19   \n",
            "4  842613459    False   finalized                   3     12/5/15 17:48   \n",
            "\n",
            "   positivity  positivity:confidence relevance  relevance:confidence  \\\n",
            "0         3.0                 0.6400       yes                 0.640   \n",
            "1         NaN                    NaN        no                 1.000   \n",
            "2         NaN                    NaN        no                 1.000   \n",
            "3         NaN                 0.0000        no                 0.675   \n",
            "4         3.0                 0.3257       yes                 0.640   \n",
            "\n",
            "       articleid      date                                           headline  \\\n",
            "0  wsj_398217788   8/14/91              Yields on CDs Fell in the Latest Week   \n",
            "1  wsj_399019502   8/21/07  The Morning Brief: White House Seeks to Limit ...   \n",
            "2  wsj_398284048  11/14/91  Banking Bill Negotiators Set Compromise --- Pl...   \n",
            "3  wsj_397959018   6/16/86  Manager's Journal: Sniffing Out Drug Abusers I...   \n",
            "4  wsj_398838054   10/4/02  Currency Trading: Dollar Remains in Tight Rang...   \n",
            "\n",
            "   positivity_gold  relevance_gold  \\\n",
            "0              NaN             NaN   \n",
            "1              NaN             NaN   \n",
            "2              NaN             NaN   \n",
            "3              NaN             NaN   \n",
            "4              NaN             NaN   \n",
            "\n",
            "                                                text  \n",
            "0  NEW YORK -- Yields on most certificates of dep...  \n",
            "1  The Wall Street Journal Online</br></br>The Mo...  \n",
            "2  WASHINGTON -- In an effort to achieve banking ...  \n",
            "3  The statistics on the enormous costs of employ...  \n",
            "4  NEW YORK -- Indecision marked the dollar's ton...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-procesamiento\n",
        "# Cargar spaCy y stopwords\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "def preprocess(text):\n",
        "    # Tokenización\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    # Quitar stopwords y signos\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "    # Lematización\n",
        "    doc = nlp(\" \".join(tokens))\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    return lemmas"
      ],
      "metadata": {
        "id": "ck3V1CBvS_Co",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "e066311b-aa46-42fc-ad34-15c6c9880d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'spacy' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3f1b412171da>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Pre-procesamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Cargar spaCy y stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"es_core_news_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spanish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Procesamiento por lotes con spaCy (mucho más rápido)\n",
        "texts = df['text'].fillna(\"\").tolist()\n",
        "labels = df['relevance'].map({'yes': 1, 'no': 0}).fillna(0).astype(int).tolist()\n",
        "\n",
        "# Procesar por lotes\n",
        "docs = list(nlp.pipe(texts, disable=[\"parser\", \"ner\"]))\n",
        "\n",
        "# Extraer tokens lematizados\n",
        "processed_tokens = [\n",
        "    [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
        "    for doc in docs\n",
        "]\n",
        "\n",
        "# Guardar en el DataFrame\n",
        "df['tokens'] = processed_tokens"
      ],
      "metadata": {
        "id": "DtVjQydJTK4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar valores únicos para verificar\n",
        "print(\"Valores únicos en 'relevance':\")\n",
        "print(df['relevance'].str.strip().str.lower().value_counts(dropna=False))\n",
        "\n",
        "# Mapear valores válidos\n",
        "def clean_relevance(value):\n",
        "    value = str(value).strip().lower()\n",
        "    if value in ['yes', 'y']:\n",
        "        return 1\n",
        "    elif value in ['no', 'n']:\n",
        "        return 0\n",
        "    else:\n",
        "        return None  # Marcar como NaN para eliminar después\n",
        "\n",
        "df['relevance'] = df['relevance'].apply(clean_relevance)\n",
        "df = df[df['relevance'].notna()]  # Eliminar filas con valores no definidos\n",
        "df['relevance'] = df['relevance'].astype(int)  # Convertir a enteros\n",
        "\n",
        "# Verificar distribución después de limpiar\n",
        "print(\"\\n✅ Distribución después de limpiar:\")\n",
        "print(df['relevance'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5NSvyYaTK6j",
        "outputId": "e931ec03-4556-4970-81bd-6fbbad9f5d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores únicos en 'relevance':\n",
            "relevance\n",
            "no          6571\n",
            "yes         1420\n",
            "not sure       9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✅ Distribución después de limpiar:\n",
            "relevance\n",
            "0    6571\n",
            "1    1420\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-8f15bb77c51a>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['relevance'] = df['relevance'].astype(int)  # Convertir a enteros\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Observacion de relevance pre-balanceo\n",
        "print(\"Distribución de 'relevance' antes del balanceo:\")\n",
        "print(df['relevance'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV06IOTjTK8x",
        "outputId": "3b430a79-a258-4723-963c-523cc4a622ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución de 'relevance' antes del balanceo:\n",
            "relevance\n",
            "0    6571\n",
            "1    1420\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar clases\n",
        "df_relevant = df[df['relevance'] == 1]\n",
        "df_not_relevant = df[df['relevance'] == 0]\n",
        "\n",
        "# Verificar que ambas clases tengan muestras\n",
        "if len(df_relevant) == 0 or len(df_not_relevant) == 0:\n",
        "    print(\"⚠️ Una de las clases está vacía. No se puede balancear.\")\n",
        "else:\n",
        "    # Submuestrear la clase mayoritaria (no relevante)\n",
        "    df_balanced = pd.concat([\n",
        "        df_relevant,\n",
        "        resample(df_not_relevant,\n",
        "                 replace=False,\n",
        "                 n_samples=len(df_relevant),\n",
        "                 random_state=42)\n",
        "    ]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n✅ Distribución después del balanceo:\")\n",
        "    print(df_balanced['relevance'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilBY_frpTqhf",
        "outputId": "f0614ee3-22f5-4113-a419-8bdd34eacc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Distribución después del balanceo:\n",
            "relevance\n",
            "1    1420\n",
            "0    1420\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer tokens y etiquetas del dataset balanceado\n",
        "tokens_balanced = df_balanced['tokens'].tolist()\n",
        "labels_balanced = df_balanced['relevance'].tolist()\n",
        "\n",
        "# Inicializar contadores\n",
        "vocab = set()\n",
        "word_counts = {\n",
        "    0: defaultdict(int),\n",
        "    1: defaultdict(int)\n",
        "}\n",
        "class_total_words = {0: 0, 1: 0}\n",
        "\n",
        "# Recorrer los tokens y etiquetas del dataset balanceado\n",
        "for tokens, label in zip(tokens_balanced, labels_balanced):\n",
        "    for word in tokens:\n",
        "        vocab.add(word)\n",
        "        word_counts[label][word] += 1\n",
        "        class_total_words[label] += 1\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Tamaño del vocabulario: {vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10C_JZbRT90G",
        "outputId": "132a4127-4142-4610-bd66-3bf57bbc78e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del vocabulario: 22849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suavizado (Laplace smoothing)\n",
        "alpha = 1.0\n",
        "\n",
        "# Probabilidad logarítmica de cada palabra por clase\n",
        "log_class_word_probs = {\n",
        "    0: {},\n",
        "    1: {}\n",
        "}\n",
        "\n",
        "for label in [0, 1]:\n",
        "    total_words_in_class = class_total_words[label]\n",
        "\n",
        "    for word in vocab:\n",
        "        count = word_counts[label].get(word, 0)\n",
        "        # Probabilidad P(palabra | clase) con suavizado\n",
        "        prob = (count + alpha) / (total_words_in_class + alpha * vocab_size)\n",
        "        log_class_word_probs[label][word] = math.log(prob)"
      ],
      "metadata": {
        "id": "QLuWHtswT95q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  calcula las probabilidades a priori para un problema de clasificación binaria:\n",
        "total_docs = len(labels_balanced)\n",
        "class_counts = {\n",
        "    0: sum(1 for label in labels_balanced if label == 0),\n",
        "    1: sum(1 for label in labels_balanced if label == 1)\n",
        "}\n",
        "\n",
        "class_priors = {\n",
        "    0: class_counts[0] / total_docs,\n",
        "    1: class_counts[1] / total_docs\n",
        "}\n",
        "\n",
        "print(\"Priors:\")\n",
        "print(class_priors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss3YU4UIT99_",
        "outputId": "150d18b6-5042-464a-88ef-3e1c3660a9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Priors:\n",
            "{0: 0.5, 1: 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predice la clase de un texto usando un clasificador Naive Bayes multinomial.\n",
        "# Recibe #text : str (el texto de entrada que se desea clasificar) y retorna un valor según\n",
        "#La clase predicha: 0 o 1, dependiendo de cuál tenga mayor probabilidad logarítmica.\n",
        "\n",
        "def predict(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [\n",
        "        token.lemma_.lower() for token in doc\n",
        "        if not token.is_stop and token.is_alpha\n",
        "    ]\n",
        "\n",
        "    # Inicializar probabilidades logarítmicas con los priors\n",
        "    log_prob = {\n",
        "        0: math.log(class_priors[0]),\n",
        "        1: math.log(class_priors[1])\n",
        "    }\n",
        "\n",
        "    MIN_LOG_PROB = math.log(1e-10)  # Para palabras no vistas en entrenamiento\n",
        "\n",
        "    for label in [0, 1]:\n",
        "        for word in tokens:\n",
        "            # Obtener probabilidad logarítmica o usar un valor por defecto\n",
        "            word_log_prob = log_class_word_probs[label].get(word, MIN_LOG_PROB)\n",
        "            log_prob[label] += word_log_prob\n",
        "\n",
        "    return 1 if log_prob[1] > log_prob[0] else 0"
      ],
      "metadata": {
        "id": "UYVrcIyrT-AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones sobre el dataset balanceado\n",
        "y_pred = [predict(text) for text in df_balanced['text']]\n",
        "y_true = df_balanced['relevance'].tolist()"
      ],
      "metadata": {
        "id": "z55vvrVUT-Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizacion de metricas\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    target_names=['No Relevante', 'Relevante'],\n",
        "    digits=4\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "h0hot91FUpz8",
        "outputId": "0ef701c3-e69f-4b6a-ec31-2cd29ce45403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'classification_report' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2577a927b3bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualizacion de metricas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m print(classification_report(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'No Relevante'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Relevante'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluacion de funcionmiento del modelo con ejemplos\n",
        "test_texts = [\n",
        "    \"The Fed raised interest rates again, signaling tighter monetary policy.\",\n",
        "    \"A new movie broke box office records this weekend.\",\n",
        "    \"Oil prices fell sharply due to oversupply and weak demand.\",\n",
        "    \"How to cook the perfect lasagna at home.\"\n",
        "]\n",
        "\n",
        "for t in test_texts:\n",
        "    print(\"Texto:\", t[:50] + \"...\")  # Muestra solo parte del texto\n",
        "    print(\"Predicción:\", \"Relevante\" if predict(t) == 1 else \"No relevante\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "weuxWhwvU26G",
        "outputId": "aa8fdad7-b9e0-4198-f119-e448ef054e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto: The Fed raised interest rates again, signaling tig...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'predict' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e0c334712232>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Texto:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Muestra solo parte del texto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicción:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Relevante\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"No relevante\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
          ]
        }
      ]
    }
  ]
}